<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link rel="stylesheet" href="../../css/blogpost.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/mono-blue.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/highlight.min.js"></script>
</head>
<body>

    <div class="menu-container">

        <div class="blue-bar"></div>
        <span><a href="#GSoC"  class="menu-item active">What is Google Summer of Code?</a></span>

        <span><a href="#Monte-Carlo" class="menu-item">Monte Carlo Simulations</a></span>

        <span><a href="#GANs" class="menu-item">Generative Adversarial Networks</a></span>

        <span><a href="#QGANs" class="menu-item">Quantum Generative Adversarial Networks</a></span>

        <span><a href="#Simulating-random-variables" class="menu-item">Simulating random variables with QGANs</a></span>

    </div>

    <header>
        <div class="container">
            <div class="logo-blog">
                <img src="../../images/Rey-logo.png" alt="Rey Guadarrama">
                <span class="logo-blog-text">Rey Guadarrama</span>
            </div>
            <nav class="header-navbar">
                <div class="menu-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </div>
                <ul>
                    <li><a href="../../index.html">HOME</a></li>
                    <li><a href="../../html/about.html">ABOUT</a></li>
                    <li><a href="../../html/portfolio.html">PORTFOLIO</a></li>
                    <li><a href="../../html/blog.html">BLOG</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <main>
        <article class="blog-post">
            <div class="post-header">
                <h1 class="post-title">GSoC 2024 | QGANs for Monte Carlo Simulations</h1>
                <div class="post-meta">
                    <img src="../../images/me.png" alt="Avatar del autor" class="author-avatar">
                    <div>
                        <span class="author-name">Luis Rey Vargaz Guadarrama</span>
                        <br>
                        <time datetime="2024-07-12">july 13, 2024</time>
                    </div>
                </div>
            </div>
            <div class="post-content">
                <section id="GSoC" class="anchor-target">
                    <h2>What is Google Summer of Code?</h2>
                    <p>
                        I spent the last summer working in GSoC 2024 with ML4SC organization. Google Summer 
                        of Code is an international, online program designed to introduce 
                        new contributors to open source software development. During this program, GSoC 
                        participants collaborate with an open source organization on a programming project 
                        lasting 12 weeks or more, under the supervision of mentors. My experience in GSoC was 
                        one of the most enriching and challenging in my life. My project is QGANs for Monte
                        Carlo Simulations and aims to explore the feasibility of applying Quantum Generative 
                        Adversarial Networks to generate event which can be simulated through Monte Carlo Method.</p>
                    <p>
                        
                    </p>
                </section>  
                
                <section id="Monte-Carlo" class="anchor-target">
                    <h2>Monte Carlo Simulations</h2>
                    <p>
                        Monte Carlo Simulation is a computational technique that uses repeated random sampling to 
                        estimate the probability of various outcomes in uncertain scenarios. Developed by John von 
                        Neumann and Stanislaw Ulam during World War II, it is named after the Monte Carlo casino due 
                        to its reliance on chance. The method is widely used in fields like finance, project management, 
                        and AI for risk assessment and decision-making. It involves setting up a predictive model, 
                        specifying probability distributions for input variables, and running several simulations to 
                        generate a range of possible outcomes.
                    </p>

                    <p>
                        Monte Carlo Simulation differs from typical forecasting models by predicting a range of outcomes 
                        based on estimated values rather than fixed inputs. It builds a model using probability 
                        distributions for variables with inherent uncertainty. By recalculating results repeatedly with
                        different random values, often thousands of times, it generates a wide array of possible outcomes.
                    </p>
                </section>

                <section id="GANs" class="anchor-target">
                    <h2>Generative Adversarial Networks</h2>

                    <p>
                        Generative Adversarial Networks (GANs) are a framework for estimating generative models using an 
                        adversarial process <a href="#ref1" class="citation" id="cite">[1]</a>. This involves training two models simultaneously:
                        a generative model \(G\) that captures the data distribution and a discriminative model \(D\) that distinguishes 
                        between samples from the true data distribution and those produced by \(G\). The goal is to improve  so that 
                        \(D\) cannot distinguish between real and generated data. This is similar to a minimax two-player game, where \(G\) 
                        tries to fool \(D\) and \(D\) aims to detect the fake data. \(D\) is trainned to maximize the probability of
                        assigning the correct label to both the true data samples and the generated samples from \(G\). Simultaneously
                        \(G\) is trainned to minimize the probabilitiy of \(D\) correctly distinguish between true an generated samples. 
                        This is done by optimizing the loss function
                        
                        \[V(D, G) = \mathbb{E}_{\mathbf{x} \sim p_{\text{data}}(\mathbf{x})} [\log D(\mathbf{x})] + 
                        \mathbb{E}_{\mathbf{z} \sim p_{\mathbf{z}}(\mathbf{z})} [\log (1 - D(G(\mathbf{z})))] \]

                        where \(D(\mathbf{x})\) represents the probability that \(\mathbf{x}\) came from the true data and \(D(G(\mathbf{z}))\) the probability of 
                        \(D\) correctly labeling a generated sample \(G(\mathbf{z})\) from the latent space \(\mathbf{z}\).   
                    
                    </p>

                    <figure>
                        <img src="../../images/GAN_diagram.png" alt="GAN-diagram" style="max-width: 100%; height: auto;">
                        <figcaption>Diagram of a GAN.</figcaption>
                    </figure>
                </section>

                <section id="QGANs" class="anchor-target">
                    <h2>Quantum Generative Adversarial Networks</h2>

                    <p>
                        Quantum Generative Adversarial Networks (QGANs) represent a quantum extension of classical GANs, incorporating 
                        quantum mechanics to leverate the computational advanteges of quantum systems <a href="#ref2" class="citation" id="cite">[2]</a>
                        <a href="#ref2" class="citation" id="cite">[3]</a>. In QGANs the generator is a parametrized quantum circuit which produces 
                        quantum states that resembles the distribution from the training data, while the discriminator can 
                        be either a classical discriminator or a quantum parametrized circuit which differentiate between 
                        the real and generated distribution.

                    </p>

                    <figure>
                        <img src="../../images/QGAN_diagram.png" alt="QGAN-diagram" style="max-width: 100%; height: auto;">
                        <figcaption>Diagram of a QGAN composed by a quantum generator and a classical discriminator.</figcaption>
                    </figure>
                </section>
                
                <section id="Simulating-random-variables" class="anchor-target">
                    <h2>Simulating random variables with QGANs</h2>

                    <p>
                        One of the key steps for Monte Carlo Method is specify the probability distribution of independent variables,
                        an incorrect choice of the distribution can lead to inaccuracies. In my project I try to address this difficulty 
                        by implementing QGANs for Monte Carlo Simulations. I used the architecture proposed by Zoufal et. al.
                        <a href="#ref3" class="citation" id="cite">[4]</a> composed by a quantum generator with an equal superposition as reference 
                        state followed by layers of parametrized \(\text{Pauli-Y}\) rotations followed by an entangling block of 
                        \(\text{control-Z}\) gates and a classical discriminator consisting in a dense neural network.
                    </p>
                    
                    <figure style="position: relative;">
                        <div style="display: flex; justify-content: space-between; position: relative;">
                            <div style="position: relative; display: inline-block;">
                                <img src="../../images/single_layer.png" alt="QGAN-diagram1" style="max-width: 85%; height: auto;">
                                <span style="position: absolute; top: 0; left: 0; background-color: rgba(255, 255, 255, 0.5); padding: 2px;"><i>a)</i></span>
                            </div>
                            <div style="position: relative; display: inline-block;">
                                <img src="../../images/Quantum-generator.png" alt="QGAN-diagram2" style="max-width: 85%; height: auto;">
                                <span style="position: absolute; top: 0; left: 0; background-color: rgba(255, 255, 255, 0.5); padding: 2px;"><em>b)</em></span>
                            </div>
                        </div>
                        <figcaption><i>a)</i> Shows a single layer of the parametrized circuit. <i>b)</i> shows the parametrized circuit 
                            corresponding to the quantum generator.</figcaption>
                    </figure>
                    
                    <p>
                        The implementation was done using pennylane and pytorch. The generator circuit 
                        returns the probabilities of the basis states, each state representing a posible outcome. The circuit takes a weights
                        parameter and as the name indicates, this is an array with the angle of rotation of each parametrized \(\text{Pauli-Y}\)
                        rotation. 
                    </p>

                    <div class="code-block">
                        <pre><code class="language-python">dev = qml.device("default.qubit", wires=n_qubits)

    @qml.qnode(dev, diff_method="backprop")
    def quantum_circuit(weights):
    """Quantum generator's parametrized circuit"""

        weights = weights.reshape(q_depth, n_qubits)

        # Initialise latent vectors
        for i in range(n_qubits):
            qml.Hadamard(wires=i)

        # Repeat each layer
        for i in range(q_depth):
            # Parameterised layer
            for y in range(n_qubits):
                qml.RY(weights[i][y], wires=y)

            # Entangling blocks of control Z gates
            for y in range(n_qubits - 1):
                qml.CZ(wires=[y, y + 1])

            qml.Barrier(wires=list(range(n_qubits)), only_visual=True)

        return qml.probs(wires=list(range(n_qubits)))</code></pre>
                    </div>

                    <p>
                        The classical discriminator is a fully connected neural network with two hidden layers, consisting in 50 and 20 nodes respectively
                        along with a LeakyRelu activation function both, finally an output layer of a single node with a sigmoid activation function to
                        return the probability of a input to be a real sample. The input layer shape depends on the number of possible outcomes the random 
                        variable of the training data can take. The input of the discriminator are the pseudo-probabilities of a batch of samples from the
                        random variable. 
                    </p>

                    <div class="code-block">
                        <pre><code class="language-python">class Discriminator(nn.Module):
        """Fully connected classical discriminator"""

        def __init__(self):
            super().__init__()

            self.model = nn.Sequential(
                # Inputs to first hidden layer (num_input_features -> 50)
                nn.Linear(num_input_features, 50),
                nn.LeakyReLU(),

                # First hidden layer (50 -> 20)
                nn.Linear(50, 20),
                nn.LeakyReLU(),
                
                # Second hidden layer (20 -> 1)
                nn.Linear(20, 1),
                nn.Sigmoid(),
            )

        def forward(self, x):
            x = x.reshape(x.size(0), -1)
            
            return self.model(x)</code></pre>
                    </div>
                    

                    <p>
                        I chose four simple scenarios to simulate: Rolling of two six-sided dice, coin toss sequences, particle time decay
                        and two dimensional random walk.
                    </p>


                    <figure>
                        <div style="position: relative; margin-bottom: 20px;">
                            <img src="../../images/coin_toss_result.png" alt="coin-toss" style="width: 100%; height: auto;">
                            <span style="position: absolute; top: 0; left: 0; background-color: rgba(255, 255, 255, 0.5); padding: 2px;"><em>a)</em></span>
                        </div>
                        <div style="position: relative;">
                            <img src="../../images/rolling_dice.png" alt="rolling-dice" style="width: 100%; height: auto;">
                            <span style="position: absolute; top: 0; left: 0; background-color: rgba(255, 255, 255, 0.5); padding: 2px;"><em>b)</em></span>
                        </div>
                        <div style="position: relative;">
                            <img src="../../images/particle_decay.png" alt="particle-decay" style="width: 100%; height: auto;">
                            <span style="position: absolute; top: 0; left: 0; background-color: rgba(255, 255, 255, 0.5); padding: 2px;"><em>c)</em></span>
                        </div>
                        <div style="position: relative;">
                            <img src="../../images/random_walk.png" alt="random-walk" style="width: 100%; height: auto;">
                            <span style="position: absolute; top: 0; left: 0; background-color: rgba(255, 255, 255, 0.5); padding: 2px;"><em>d)</em></span>
                        </div>
                        <figcaption>Diagramas de un QGAN compuesto por un generador cuántico y un discriminador clásico.</figcaption>
                    </figure>
                </section>


                <div class="code-block">
                    <pre><code class="language-python">def factorial(n):
    if n == 0:
        return 1
    else:
        return n * factorial(n - 1)

print(factorial(5))  # Salida: 120</code></pre>
                </div>
                

                <h2>References</h2>
                    <div id="references">
                        <p id="ref1">[1] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, 
                            Sherjil Ozair, Aaron Courville and Yoshua Bengio, <strong>Generative Adversarial Networks</strong>,
                            <a href="https://arxiv.org/abs/1406.2661" id="cite" target="_blank">arXiv:1406.2661v1 </a>.</p>

                        <p id="ref2">[2] Pierre-Luc Dallaire-Demers, <strong>Quantum Generative Adversarial Networks</strong>,
                        <a href="https://arxiv.org/abs/1804.08641" id="cite" target="_blank">arXiv:1804.08641v2 </a>.</p>

                        <p id="ref3">[3] Seth Lloyd, Christian Weedbrook, <strong>Quantum Generative Adversarial Learning</strong>,
                        <a href="https://arxiv.org/abs/1804.09139" id="cite" target="_blank">arXiv:1804.09139v1 </a>.</p>

                        <p id="ref4">[4] Zoufal, C., Lucchi, A., & Woerner, S. (2019). <strong>Quantum Generative Adversarial Networks for 
                            learning and loading random distributions</strong>. Npj Quantum Information, 5(1).
                            <a href="https://www.nature.com/articles/s41534-019-0223-2" id="cite" target="_blank">https://doi.org/10.1038/s41534-019-0223-2 </a>.</p>
                    </div>

            </div>
        </article>
    </main>

    <footer>
        <div class="social-icons">
            <a href="https://www.linkedin.com/in/reyguadarrama/" target="_blank"><i class="fab fa-linkedin-in"></i></a>
            <a href="https://github.com/ReyGuadarrama" target="_blank"><i class="fab fa-github"></i></a>
            <a href="mailto:luisrey7.lrv@gmail.com"><i class="fas fa-envelope"></i></a>
        </div>
        <p class="copyright">&copy; All rights reserved.</p>
    </footer>
    
    <script src="../../js/blogpost.js"></script>
</body>
</html>